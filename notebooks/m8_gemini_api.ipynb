{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "186f0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "097afb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using repo root: /Users/rambodparsi/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis\n",
      "Bootstrap ready ✓\n"
     ]
    }
   ],
   "source": [
    "# === Bootstrap cell: shared config, paths, JSON I/O, and GitHub REST/GraphQL helpers ===\n",
    "\n",
    "import os, json, time, re, random, pathlib\n",
    "from typing import Dict, Any, Optional, Tuple, List\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import requests\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Locate repo root reliably (works no matter where you open the .ipynb)\n",
    "# -------------------------------------------------------------------\n",
    "def _find_repo_root(start: pathlib.Path) -> pathlib.Path:\n",
    "    cur = start.resolve()\n",
    "    for _ in range(8):  # walk up to 8 levels\n",
    "        if (cur / \"config\" / \"config.yaml\").exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "    raise FileNotFoundError(\"Couldn't locate repo root (no config/config.yaml found upward).\")\n",
    "\n",
    "REPO_ROOT = _find_repo_root(pathlib.Path.cwd())\n",
    "CONFIG_PATH = REPO_ROOT / \"config\" / \"config.yaml\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Load config + token\n",
    "# -------------------------------------------------------------------\n",
    "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    CFG: Dict[str, Any] = yaml.safe_load(f) or {}\n",
    "\n",
    "load_dotenv(REPO_ROOT / \".env\")  # local only; do not commit .env\n",
    "TOKEN_ENV = (CFG.get(\"github_token_env\") or \"GITHUB_TOKEN\").strip()\n",
    "GITHUB_TOKEN = os.getenv(TOKEN_ENV, \"\").strip()\n",
    "if not GITHUB_TOKEN:\n",
    "    raise RuntimeError(f\"Missing token in environment variable {TOKEN_ENV}. \"\n",
    "                       f\"Create .env from .env.example and set {TOKEN_ENV}=...\")\n",
    "\n",
    "# Repo + output root\n",
    "REPO = CFG[\"repo\"]  # \"owner/name\"\n",
    "OWNER, NAME = REPO.split(\"/\", 1)\n",
    "OUT_ROOT = pathlib.Path(CFG.get(\"out_root\") or NAME)  # \"<name>\" if null\n",
    "\n",
    "# Behavior\n",
    "OVERWRITE = bool(CFG.get(\"overwrite\", True))\n",
    "VERBOSE = bool(CFG.get(\"verbose_logs\", True))\n",
    "\n",
    "# Networking knobs\n",
    "REQ_TIMEOUT = int(CFG.get(\"request_timeout_sec\", 30))\n",
    "MAX_RETRIES = int(CFG.get(\"max_retries\", 4))\n",
    "BACKOFF_BASE_MS = int(CFG.get(\"backoff_base_ms\", 400))\n",
    "BACKOFF_JITTER_MS = int(CFG.get(\"backoff_jitter_ms\", 250))\n",
    "RESPECT_RL = bool(CFG.get(\"respect_rate_limits\", True))\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Tiny logging helpers\n",
    "# -------------------------------------------------------------------\n",
    "def log(msg: str) -> None:\n",
    "    if VERBOSE:\n",
    "        print(msg, flush=True)\n",
    "\n",
    "def warn(msg: str) -> None:\n",
    "    print(f\"⚠️  {msg}\", flush=True)\n",
    "\n",
    "print(\"Using repo root:\", REPO_ROOT)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Canonical output layout helpers\n",
    "# -------------------------------------------------------------------\n",
    "def ensure_dir(p: pathlib.Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def repo_root() -> pathlib.Path:\n",
    "    root = OUT_ROOT\n",
    "    ensure_dir(root)\n",
    "    return root\n",
    "\n",
    "def tags_all_json() -> pathlib.Path:\n",
    "    d = repo_root() / \"tags\"\n",
    "    ensure_dir(d)\n",
    "    return d / \"tags.all.json\"\n",
    "\n",
    "def series_dir(kind: str, series: str) -> pathlib.Path:\n",
    "    d = repo_root() / kind / series\n",
    "    ensure_dir(d)\n",
    "    return d\n",
    "\n",
    "def pair_stem(base: str, compare: str) -> str:\n",
    "    return f\"{base}...{compare}\"\n",
    "\n",
    "def pair_json(series: str, stem: str, kind: str) -> pathlib.Path:\n",
    "    # kind ∈ {\"compare\",\"commits\",\"pulls\",\"issues\"}\n",
    "    return series_dir(kind, series) / f\"{stem}.{kind}.json\"\n",
    "\n",
    "def capsule_json(series: str, stem: str) -> pathlib.Path:\n",
    "    return series_dir(\"commits_pr_issue\", series) / f\"{stem}.tarce_artifacts.json\"\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# JSON I/O\n",
    "# -------------------------------------------------------------------\n",
    "def read_json(path: pathlib.Path) -> Optional[Dict[str, Any]]:\n",
    "    if not path.exists():\n",
    "        return None\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def write_json(path: pathlib.Path, payload: Dict[str, Any]) -> None:\n",
    "    ensure_dir(path.parent)\n",
    "    if path.exists() and not OVERWRITE:\n",
    "        log(f\"Skip (exists): {path}\")\n",
    "        return\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    with open(tmp, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "    tmp.replace(path)\n",
    "    log(f\"✓ Wrote {path}\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# GitHub HTTP session + rate-limit aware helpers\n",
    "# -------------------------------------------------------------------\n",
    "SESSION = requests.Session()\n",
    "SESSION.headers.update({\n",
    "    \"Authorization\": f\"Bearer {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github+json\",\n",
    "    \"X-GitHub-Api-Version\": \"2022-11-28\",\n",
    "    \"User-Agent\": f\"notebook-pipeline/{NAME}\"\n",
    "})\n",
    "\n",
    "def _parse_reset_epoch(headers: Dict[str, Any]) -> Optional[int]:\n",
    "    try:\n",
    "        return int(headers.get(\"X-RateLimit-Reset\") or headers.get(\"x-ratelimit-reset\"))\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _maybe_sleep_for_reset(resp: requests.Response) -> None:\n",
    "    if not RESPECT_RL:\n",
    "        return\n",
    "    remaining = resp.headers.get(\"X-RateLimit-Remaining\") or resp.headers.get(\"x-ratelimit-remaining\")\n",
    "    if remaining is not None and str(remaining).isdigit() and int(remaining) <= 0:\n",
    "        reset_epoch = _parse_reset_epoch(resp.headers)\n",
    "        if reset_epoch:\n",
    "            now = int(time.time())\n",
    "            delta = max(0, reset_epoch - now) + 1\n",
    "            warn(f\"Rate limit reached. Sleeping ~{delta}s until reset …\")\n",
    "            time.sleep(delta)\n",
    "\n",
    "def _backoff_sleep(i: int) -> None:\n",
    "    base = BACKOFF_BASE_MS / 1000.0\n",
    "    jitter = random.uniform(0, BACKOFF_JITTER_MS / 1000.0)\n",
    "    time.sleep((2 ** i) * base + jitter)\n",
    "\n",
    "def rest_get_json(url: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generic GET with backoff + rate-limit handling.\n",
    "    \"\"\"\n",
    "    last_err = None\n",
    "    for i in range(MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = SESSION.get(url, params=params, timeout=REQ_TIMEOUT)\n",
    "            # Honor 429 Retry-After if present\n",
    "            if r.status_code == 429:\n",
    "                ra = r.headers.get(\"Retry-After\")\n",
    "                if ra and ra.isdigit():\n",
    "                    wait_s = int(ra)\n",
    "                    warn(f\"429 received. Sleeping {wait_s}s per Retry-After …\")\n",
    "                    time.sleep(wait_s)\n",
    "                    continue\n",
    "            if r.status_code >= 500:\n",
    "                last_err = f\"{r.status_code} {r.text[:200]}\"\n",
    "                _backoff_sleep(i)\n",
    "                continue\n",
    "            if r.status_code >= 400:\n",
    "                raise RuntimeError(f\"HTTP {r.status_code}: {r.text[:500]}\")\n",
    "            _maybe_sleep_for_reset(r)\n",
    "            return r.json()\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "            _backoff_sleep(i)\n",
    "    raise RuntimeError(f\"GET failed after retries: {url} :: {last_err}\")\n",
    "\n",
    "def gh_graphql(query: str, variables: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    GitHub GraphQL POST with backoff + rate-limit handling.\n",
    "    Endpoint: https://api.github.com/graphql\n",
    "    \"\"\"\n",
    "    url = \"https://api.github.com/graphql\"\n",
    "    payload = {\"query\": query, \"variables\": variables or {}}\n",
    "    last_err = None\n",
    "    for i in range(MAX_RETRIES + 1):\n",
    "        try:\n",
    "            r = SESSION.post(url, json=payload, timeout=REQ_TIMEOUT)\n",
    "            if r.status_code == 429:\n",
    "                ra = r.headers.get(\"Retry-After\")\n",
    "                if ra and ra.isdigit():\n",
    "                    wait_s = int(ra)\n",
    "                    warn(f\"429 received. Sleeping {wait_s}s per Retry-After …\")\n",
    "                    time.sleep(wait_s)\n",
    "                    continue\n",
    "            if r.status_code >= 500:\n",
    "                last_err = f\"{r.status_code} {r.text[:200]}\"\n",
    "                _backoff_sleep(i)\n",
    "                continue\n",
    "            if r.status_code >= 400:\n",
    "                raise RuntimeError(f\"GraphQL HTTP {r.status_code}: {r.text[:500]}\")\n",
    "            _maybe_sleep_for_reset(r)\n",
    "            data = r.json()\n",
    "            if \"errors\" in data:\n",
    "                last_err = f\"GraphQL errors: {data['errors']}\"\n",
    "                _backoff_sleep(i)\n",
    "                continue\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            last_err = str(e)\n",
    "            _backoff_sleep(i)\n",
    "    raise RuntimeError(f\"GraphQL failed after retries: {last_err}\")\n",
    "\n",
    "def rate_limit_snapshot() -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Returns current REST rate-limit bucket (printed; not written to JSON outputs).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        info = rest_get_json(\"https://api.github.com/rate_limit\")\n",
    "        core = info.get(\"resources\", {}).get(\"core\", {})\n",
    "        remaining = core.get(\"remaining\")\n",
    "        limit = core.get(\"limit\")\n",
    "        reset = core.get(\"reset\")\n",
    "        when = datetime.fromtimestamp(reset, tz=timezone.utc).isoformat() if reset else None\n",
    "        snap = {\"limit\": limit, \"remaining\": remaining, \"reset_epoch\": reset, \"reset_iso\": when}\n",
    "        log(f\"Rate limit: {remaining}/{limit}, resets at {when}\")\n",
    "        return snap\n",
    "    except Exception as e:\n",
    "        warn(f\"Rate limit snapshot failed: {e}\")\n",
    "        return {}\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Light helpers for series + ordering\n",
    "# -------------------------------------------------------------------\n",
    "def semver_series(tag_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract 'vX.Y' series from tags like 'v4.2.3', '4.2.0-rc.1', etc.\n",
    "    Falls back to 'v0.0' if not parseable.\n",
    "    \"\"\"\n",
    "    m = re.search(r'v?(\\d+)\\.(\\d+)', tag_name or \"\")\n",
    "    if not m:\n",
    "        return \"v0.0\"\n",
    "    return f\"v{int(m.group(1))}.{int(m.group(2))}\"\n",
    "\n",
    "def sorted_pairs_by_tag_time(pairs: List[Tuple[str, str]], tag_index: Dict[str, Dict[str, Any]]) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    Sort (base, compare) by tag timestamps ascending when both are tags;\n",
    "    unknown timestamps sort last.\n",
    "    \"\"\"\n",
    "    def ts(tag: str) -> float:\n",
    "        rec = tag_index.get(tag)\n",
    "        if rec and rec.get(\"tag_timestamp\"):\n",
    "            try:\n",
    "                return datetime.fromisoformat(rec[\"tag_timestamp\"].replace(\"Z\", \"+00:00\")).timestamp()\n",
    "            except Exception:\n",
    "                pass\n",
    "        return float(\"inf\")\n",
    "    return sorted(pairs, key=lambda bc: (ts(bc[0]), ts(bc[1])))\n",
    "\n",
    "log(\"Bootstrap ready ✓\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d955b1",
   "metadata": {},
   "source": [
    "### Message creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc6c052b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo: mastodon/mastodon\n",
      "repo_root(): mastodon\n",
      "Loaded prompt file: /Users/rambodparsi/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/prompt\n",
      "------------------------------------------------------------\n",
      "Prompt preview (first 300 chars):\n",
      "You are an expert GitHub developer and contributor for a web application. Your job is to analyze a GitHub issue (title + body) and classify it into one of exactly two classes: \"UI\" or \"Other\". Follow the class definitions below precisely. Then output a SINGLE JSON object in the required schema. Do n…\n",
      "\n",
      "Found CSVs: ['v4.0.csv', 'v4.1.csv', 'v4.2.csv', 'v4.3.csv', 'v4.4.csv']\n",
      "Applied series_whitelist=['v4.3'] → 1/5 remain\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, textwrap, csv\n",
    "\n",
    "print(\"Repo:\", REPO)\n",
    "print(\"repo_root():\", repo_root())\n",
    "\n",
    "# 1) Load the base prompt text (exact filename \"prompt\" at repo root)\n",
    "prompt_path = Path(REPO_ROOT) / \"prompt\"\n",
    "if not prompt_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Couldn't find {prompt_path}. Create a text file named 'prompt' at the repo root.\"\n",
    "    )\n",
    "\n",
    "BASE_PROMPT = prompt_path.read_text(encoding=\"utf-8\").strip()\n",
    "print(\"Loaded prompt file:\", prompt_path)\n",
    "print(\"-\" * 60)\n",
    "print(\"Prompt preview (first 300 chars):\")\n",
    "print((BASE_PROMPT[:300] + (\"…\" if len(BASE_PROMPT) > 300 else \"\")))\n",
    "\n",
    "# 2) Find per-series CSVs produced by M7\n",
    "gi_dir = Path(repo_root()) / \"gemini_input\"\n",
    "if not gi_dir.exists():\n",
    "    raise FileNotFoundError(f\"Not found: {gi_dir}. Run M7 first to create gemini_input JSON/CSV.\")\n",
    "\n",
    "series_csvs = sorted(gi_dir.glob(\"v*.csv\"))\n",
    "print(\"\\nFound CSVs:\", [p.name for p in series_csvs])\n",
    "\n",
    "# Optional: respect series_whitelist from config\n",
    "SERIES_WHITELIST = CFG.get(\"series_whitelist\") or []\n",
    "if SERIES_WHITELIST:\n",
    "    before = len(series_csvs)\n",
    "    series_csvs = [p for p in series_csvs if p.stem in set(SERIES_WHITELIST)]\n",
    "    print(f\"Applied series_whitelist={SERIES_WHITELIST} → {len(series_csvs)}/{before} remain\")\n",
    "\n",
    "if not series_csvs:\n",
    "    print(\"⚠️  No series CSVs found to preview.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "61d12e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v4.3.csv: prepared 129 messages\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "def _clean(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    # Collapse excessive whitespace/newlines while preserving paragraphs\n",
    "    s = s.replace(\"\\r\", \"\")\n",
    "    lines = [ln.strip() for ln in s.split(\"\\n\")]\n",
    "    # Keep empty lines to preserve user formatting intent\n",
    "    while lines and lines[0] == \"\":\n",
    "        lines.pop(0)\n",
    "    while lines and lines[-1] == \"\":\n",
    "        lines.pop()\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def build_messages_from_csv(csv_path: Path, base_prompt: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Returns a list of dicts:\n",
    "      { \"sha\": ..., \"issue_title\": ..., \"issue_body\": ..., \"message\": <full text> }\n",
    "    NOTE: does not write anything to disk.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        # Expecting columns from M7 extra: sha, issue_title, issue_body, issue_lable\n",
    "        for r in reader:\n",
    "            sha  = (r.get(\"sha\") or \"\").strip()\n",
    "            it   = _clean(r.get(\"issue_title\") or \"\")\n",
    "            ib   = _clean(r.get(\"issue_body\") or \"\")\n",
    "            # You asked to classify issues (title+body). If both are empty, skip.\n",
    "            if not it and not ib:\n",
    "                continue\n",
    "\n",
    "            msg = f\"\"\"{base_prompt}\n",
    "\n",
    "Issue title: {it}\n",
    "Issue body: {ib}\"\"\"\n",
    "            rows.append({\n",
    "                \"sha\": sha,\n",
    "                \"issue_title\": it,\n",
    "                \"issue_body\": ib,\n",
    "                \"message\": msg\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "# Build messages for each selected series (in memory)\n",
    "series_to_messages: Dict[str, List[Dict]] = {}\n",
    "for csv_path in series_csvs:\n",
    "    msgs = build_messages_from_csv(csv_path, BASE_PROMPT)\n",
    "    series_to_messages[csv_path.stem] = msgs\n",
    "    print(f\"{csv_path.name}: prepared {len(msgs)} messages\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a2a5431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3 style='margin-top:24px'>v4.3 — showing 3 example messages</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border:1px solid #ddd;margin:12px 0;padding:10px;\">\n",
       "      <div style=\"font-weight:600;margin-bottom:6px;\">Example 1 (sha: 4cc589e53351a939e10887faf791ae84b15850d8)</div>\n",
       "      <pre style=\"white-space:pre-wrap;overflow:auto;max-height:480px;margin:0;\">\n",
       "You are an expert GitHub developer and contributor for a web application. Your job is to analyze a GitHub issue (title + body) and classify it into one of exactly two classes: \"UI\" or \"Other\". Follow the class definitions below precisely. Then output a SINGLE JSON object in the required schema. Do not add any extra text, explanations, code fences, or markdown—ONLY the JSON object.\n",
       "\n",
       "DEFINITIONS (exactly two classes):\n",
       "\n",
       "1) UI (User Interface)\n",
       "Description:\n",
       "- Issues that are purely visual or layout-related—the presentation layer the user directly sees.\n",
       "Examples include (non-exhaustive):\n",
       "- Readability / Cognitive Load: poor contrast, illegible fonts, dense text, inconsistent visual hierarchy.\n",
       "- Aesthetics and Styling: incorrect colors, wrong font sizes, padding/margin mistakes, misaligned elements, excessive visual clutter.\n",
       "- Layout and Responsiveness: overlapping elements, content bleeding off-screen, broken layouts on mobile/desktop, incorrect positioning.\n",
       "- Visual State Errors: incorrect hover/pressed/disabled visual states; looks enabled when disabled, etc.\n",
       "- Missing Visual Elements: expected icon/image/loader is visually missing.\n",
       "\n",
       "2) Other\n",
       "Description:\n",
       "- The default for anything NOT strictly visual/presentation.\n",
       "- Includes functional/behavioral UX, logic, performance, accessibility (interaction/ARIA/keyboard/screen reader), error handling, system feedback, data issues, or conceptual design.\n",
       "Examples include (non-exhaustive):\n",
       "- System Feedback/Function: no confirmation after save; forces memory/recall between steps.\n",
       "- Logic and Behavior: wrong calculations, data loading errors, broken form submission, violates platform conventions.\n",
       "- Error Handling: cryptic errors, no recovery, allows destructive actions too easily.\n",
       "- User Control: missing undo/redo, cannot cancel a task.\n",
       "- Accessibility (A11y): keyboard navigation failures, screen reader problems, missing ARIA labels (interaction failures are NOT purely visual).\n",
       "\n",
       "OUTPUT FORMAT (strict):\n",
       "Return ONLY a single JSON object with this exact schema and keys:\n",
       "{\n",
       "  \"reason\": \"Explain why it is UI or Other, referencing specific words/phrases from the issue that match the definitions. Name the relevant heuristic/category when applicable (e.g., Readability, Consistency and Standards, Error Prevention).\",\n",
       "  \"class\": \"UI or Other\"\n",
       "}\n",
       "\n",
       "ADDITIONAL RULES:\n",
       "- If any functional/behavioral aspect is involved, classify as \"Other\" (even if there are also minor visual complaints).\n",
       "- If the issue is ambiguous or mixes concerns, prefer \"Other\" unless it is clearly and exclusively visual/presentation.\n",
       "- Never invent details beyond the issue text.\n",
       "- Output must be valid JSON (no trailing commas, no markdown, no extra keys).\n",
       "- Keys must be exactly: \"reason\", \"class\".\n",
       "- \"class\" must be exactly one of: \"UI\" or \"Other\".\n",
       "\n",
       "ISSUE TO CLASSIFY:\n",
       "\n",
       "Issue title: Run i18n-tasks normalize\n",
       "Issue body: \n",
       "      </pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border:1px solid #ddd;margin:12px 0;padding:10px;\">\n",
       "      <div style=\"font-weight:600;margin-bottom:6px;\">Example 2 (sha: 0422a5c208dc9ca13684690c5a83e7363ca797d3)</div>\n",
       "      <pre style=\"white-space:pre-wrap;overflow:auto;max-height:480px;margin:0;\">\n",
       "You are an expert GitHub developer and contributor for a web application. Your job is to analyze a GitHub issue (title + body) and classify it into one of exactly two classes: \"UI\" or \"Other\". Follow the class definitions below precisely. Then output a SINGLE JSON object in the required schema. Do not add any extra text, explanations, code fences, or markdown—ONLY the JSON object.\n",
       "\n",
       "DEFINITIONS (exactly two classes):\n",
       "\n",
       "1) UI (User Interface)\n",
       "Description:\n",
       "- Issues that are purely visual or layout-related—the presentation layer the user directly sees.\n",
       "Examples include (non-exhaustive):\n",
       "- Readability / Cognitive Load: poor contrast, illegible fonts, dense text, inconsistent visual hierarchy.\n",
       "- Aesthetics and Styling: incorrect colors, wrong font sizes, padding/margin mistakes, misaligned elements, excessive visual clutter.\n",
       "- Layout and Responsiveness: overlapping elements, content bleeding off-screen, broken layouts on mobile/desktop, incorrect positioning.\n",
       "- Visual State Errors: incorrect hover/pressed/disabled visual states; looks enabled when disabled, etc.\n",
       "- Missing Visual Elements: expected icon/image/loader is visually missing.\n",
       "\n",
       "2) Other\n",
       "Description:\n",
       "- The default for anything NOT strictly visual/presentation.\n",
       "- Includes functional/behavioral UX, logic, performance, accessibility (interaction/ARIA/keyboard/screen reader), error handling, system feedback, data issues, or conceptual design.\n",
       "Examples include (non-exhaustive):\n",
       "- System Feedback/Function: no confirmation after save; forces memory/recall between steps.\n",
       "- Logic and Behavior: wrong calculations, data loading errors, broken form submission, violates platform conventions.\n",
       "- Error Handling: cryptic errors, no recovery, allows destructive actions too easily.\n",
       "- User Control: missing undo/redo, cannot cancel a task.\n",
       "- Accessibility (A11y): keyboard navigation failures, screen reader problems, missing ARIA labels (interaction failures are NOT purely visual).\n",
       "\n",
       "OUTPUT FORMAT (strict):\n",
       "Return ONLY a single JSON object with this exact schema and keys:\n",
       "{\n",
       "  \"reason\": \"Explain why it is UI or Other, referencing specific words/phrases from the issue that match the definitions. Name the relevant heuristic/category when applicable (e.g., Readability, Consistency and Standards, Error Prevention).\",\n",
       "  \"class\": \"UI or Other\"\n",
       "}\n",
       "\n",
       "ADDITIONAL RULES:\n",
       "- If any functional/behavioral aspect is involved, classify as \"Other\" (even if there are also minor visual complaints).\n",
       "- If the issue is ambiguous or mixes concerns, prefer \"Other\" unless it is clearly and exclusively visual/presentation.\n",
       "- Never invent details beyond the issue text.\n",
       "- Output must be valid JSON (no trailing commas, no markdown, no extra keys).\n",
       "- Keys must be exactly: \"reason\", \"class\".\n",
       "- \"class\" must be exactly one of: \"UI\" or \"Other\".\n",
       "\n",
       "ISSUE TO CLASSIFY:\n",
       "\n",
       "Issue title: Code of Conduct\n",
       "Issue body: There should be a [code of conduct](https://www.ashedryden.com/blog/codes-of-conduct-101-faq)—policies regarding community standards and inappropriate behaviour.\n",
       "\n",
       "There should be rules regarding:\n",
       "\n",
       "- what constitutes inappropriate content/behaviour\n",
       "- the consequences for inappropriate content/behaviour\n",
       "- who enforces the consequences\n",
       "- how the consequences are enforced\n",
       "- changing the rules themselves\n",
       "- under what circumstances, if any, data will be turned over to authorities\n",
       "\n",
       "And moderation features or functions that might include:\n",
       "\n",
       "- permissions for different levels of users\n",
       "- hiding or deleting individual statuses/media\n",
       "- suspension\n",
       "- account banning\n",
       "- shadowbanning (the user isn't banned, but no one else can see or interact with them)\n",
       "- IP banning\n",
       "- reporting inappropriate content/behaviour\n",
       "- contacting a Mastodon instance's mods/admins/ops\n",
       "\n",
       "Scenarios to consider:\n",
       "\n",
       "- One user is sending another user threats, harassment, or hate speech.\n",
       "- One user is inciting many people to send a user threats, harassment, or hate speech.\n",
       "- Users are using the Mastodon instance to coordinate a harassment campaign on another instance or social media platform.\n",
       "- A user who may or may not be a minor is posting explicit images of themselves.\n",
       "- A user is posting explicit images of someone else, possibly without their consent.\n",
       "- Police contact you about a user's public posts about illegal activities.\n",
       "- DMCA takedown notices.\n",
       "- Users are Nazis.\n",
       "\n",
       "Hope for the best, but plan for the worst.\n",
       "      </pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"border:1px solid #ddd;margin:12px 0;padding:10px;\">\n",
       "      <div style=\"font-weight:600;margin-bottom:6px;\">Example 3 (sha: d0822a0e78cac93cc0350e8e6abe7a89b536e836)</div>\n",
       "      <pre style=\"white-space:pre-wrap;overflow:auto;max-height:480px;margin:0;\">\n",
       "You are an expert GitHub developer and contributor for a web application. Your job is to analyze a GitHub issue (title + body) and classify it into one of exactly two classes: \"UI\" or \"Other\". Follow the class definitions below precisely. Then output a SINGLE JSON object in the required schema. Do not add any extra text, explanations, code fences, or markdown—ONLY the JSON object.\n",
       "\n",
       "DEFINITIONS (exactly two classes):\n",
       "\n",
       "1) UI (User Interface)\n",
       "Description:\n",
       "- Issues that are purely visual or layout-related—the presentation layer the user directly sees.\n",
       "Examples include (non-exhaustive):\n",
       "- Readability / Cognitive Load: poor contrast, illegible fonts, dense text, inconsistent visual hierarchy.\n",
       "- Aesthetics and Styling: incorrect colors, wrong font sizes, padding/margin mistakes, misaligned elements, excessive visual clutter.\n",
       "- Layout and Responsiveness: overlapping elements, content bleeding off-screen, broken layouts on mobile/desktop, incorrect positioning.\n",
       "- Visual State Errors: incorrect hover/pressed/disabled visual states; looks enabled when disabled, etc.\n",
       "- Missing Visual Elements: expected icon/image/loader is visually missing.\n",
       "\n",
       "2) Other\n",
       "Description:\n",
       "- The default for anything NOT strictly visual/presentation.\n",
       "- Includes functional/behavioral UX, logic, performance, accessibility (interaction/ARIA/keyboard/screen reader), error handling, system feedback, data issues, or conceptual design.\n",
       "Examples include (non-exhaustive):\n",
       "- System Feedback/Function: no confirmation after save; forces memory/recall between steps.\n",
       "- Logic and Behavior: wrong calculations, data loading errors, broken form submission, violates platform conventions.\n",
       "- Error Handling: cryptic errors, no recovery, allows destructive actions too easily.\n",
       "- User Control: missing undo/redo, cannot cancel a task.\n",
       "- Accessibility (A11y): keyboard navigation failures, screen reader problems, missing ARIA labels (interaction failures are NOT purely visual).\n",
       "\n",
       "OUTPUT FORMAT (strict):\n",
       "Return ONLY a single JSON object with this exact schema and keys:\n",
       "{\n",
       "  \"reason\": \"Explain why it is UI or Other, referencing specific words/phrases from the issue that match the definitions. Name the relevant heuristic/category when applicable (e.g., Readability, Consistency and Standards, Error Prevention).\",\n",
       "  \"class\": \"UI or Other\"\n",
       "}\n",
       "\n",
       "ADDITIONAL RULES:\n",
       "- If any functional/behavioral aspect is involved, classify as \"Other\" (even if there are also minor visual complaints).\n",
       "- If the issue is ambiguous or mixes concerns, prefer \"Other\" unless it is clearly and exclusively visual/presentation.\n",
       "- Never invent details beyond the issue text.\n",
       "- Output must be valid JSON (no trailing commas, no markdown, no extra keys).\n",
       "- Keys must be exactly: \"reason\", \"class\".\n",
       "- \"class\" must be exactly one of: \"UI\" or \"Other\".\n",
       "\n",
       "ISSUE TO CLASSIFY:\n",
       "\n",
       "Issue title: How to detect if a server is using mastodon?\n",
       "Issue body: In Friendica we are having some code that does a server detection. When a server url is entered the system detects which protocol is used the best for the server and which software in which version it using.\n",
       "\n",
       "How can we get this information (software and version) from mastodon?\n",
       "      </pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "EXAMPLES_PER_SERIES = 3  # change freely\n",
    "\n",
    "def _scroll_block(title, body, height=480):\n",
    "    # preserves newlines; wraps long lines; scrolls if very long\n",
    "    html = f\"\"\"\n",
    "    <div style=\"border:1px solid #ddd;margin:12px 0;padding:10px;\">\n",
    "      <div style=\"font-weight:600;margin-bottom:6px;\">{title}</div>\n",
    "      <pre style=\"white-space:pre-wrap;overflow:auto;max-height:{height}px;margin:0;\">\n",
    "{body}\n",
    "      </pre>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(html))\n",
    "\n",
    "for series, rows in series_to_messages.items():\n",
    "    display(HTML(f\"<h3 style='margin-top:24px'>{series} — showing {min(EXAMPLES_PER_SERIES, len(rows))} example messages</h3>\"))\n",
    "    for i, row in enumerate(rows[:EXAMPLES_PER_SERIES], start=1):\n",
    "        _scroll_block(\n",
    "            f\"Example {i} (sha: {row['sha']})\",\n",
    "            row[\"message\"]\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ef659c",
   "metadata": {},
   "source": [
    "### LLMs call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d28fbaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied series_whitelist=['v4.3'] → 1/5 remain\n",
      "Input series: ['v4.3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "v4.3:  32%|███▏      | 213/656 [32:59<1:08:37,  9.29s/row, 443 remain (skipped 8)]\n",
      "v4.3:   1%|▏         | 9/656 [00:14<22:25,  2.08s/row, 647 remain (skipped 8)]      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Gemini call failed after 3 retries: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\\nPlease retry in 46.386059128s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '200'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 88\u001b[39m, in \u001b[36mcall_gemini_classify\u001b[39m\u001b[34m(client, model, message)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m     resp = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mgetattr\u001b[39m(resp, \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/google/genai/models.py:5006\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5005\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5006\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5007\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5008\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5010\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/google/genai/models.py:3818\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3816\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3818\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3819\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3820\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3822\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   3823\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3824\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/google/genai/_api_client.py:1314\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1311\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1312\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1313\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m response_body = (\n\u001b[32m   1316\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1317\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/google/genai/_api_client.py:1150\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1150\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/tenacity/__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/tenacity/__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/google/genai/_api_client.py:1127\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1120\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1121\u001b[39m     method=http_request.method,\n\u001b[32m   1122\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1125\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1126\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1127\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1129\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1130\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/OSS Repository Selection/web_scrapper/commit_pr_issue_analysis/.venv/lib/python3.11/site-packages/google/genai/errors.py:108\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit.\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 200\\nPlease retry in 35.998909805s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}, 'quotaValue': '200'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 229\u001b[39m\n\u001b[32m    226\u001b[39m limiter.wait_for_slot()\n\u001b[32m    228\u001b[39m \u001b[38;5;66;03m# Call Gemini\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m label = \u001b[43mcall_gemini_classify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGEMINI_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m r[\u001b[33m\"\u001b[39m\u001b[33mgemini_label\u001b[39m\u001b[33m\"\u001b[39m] = label\n\u001b[32m    232\u001b[39m w.writerow(r)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 96\u001b[39m, in \u001b[36mcall_gemini_classify\u001b[39m\u001b[34m(client, model, message)\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     95\u001b[39m         last_err = e\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 1s,2s,4s,8s capped\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m⚠️  Gemini call failed after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMAX_RETRIES\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m retries: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlast_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# --- M8: Gemini classification (resumable, 8 calls/min, progress bar) ---\n",
    "import os, time, csv, json, re, unicodedata\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "\n",
    "# 0) Prompt: accept either 'prompt' or 'prompt.txt' at repo root\n",
    "prompt_path = (Path(REPO_ROOT) / \"prompt\")\n",
    "if not prompt_path.exists():\n",
    "    alt = Path(REPO_ROOT) / \"prompt.txt\"\n",
    "    if alt.exists():\n",
    "        prompt_path = alt\n",
    "if not prompt_path.exists():\n",
    "    raise FileNotFoundError(f\"Prompt file not found at {Path(REPO_ROOT) / 'prompt'} or 'prompt.txt'\")\n",
    "BASE_PROMPT = prompt_path.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "# 1) Install / import Gemini client\n",
    "try:\n",
    "    import google.genai as genai\n",
    "except Exception:\n",
    "    %pip -q install \"google-genai>=0.3.0\"\n",
    "    import google.genai as genai\n",
    "\n",
    "# 1b) tqdm for progress\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    %pip -q install \"tqdm>=4.66.0\"\n",
    "    from tqdm.auto import tqdm\n",
    "\n",
    "# 2) Read API key from .env\n",
    "GEMINI_TOKEN = os.getenv(\"GEMINI_TOKEN\", \"\").strip()\n",
    "if not GEMINI_TOKEN:\n",
    "    raise RuntimeError(\"GEMINI_TOKEN is missing. Add GEMINI_TOKEN=... to your .env and restart the kernel.\")\n",
    "\n",
    "# 3) Config\n",
    "GEMINI_MODEL = \"gemini-2.0-flash\"   # or \"gemini-2.0-pro\"\n",
    "TEMPERATURE = 0.0                   # deterministic label\n",
    "MAX_RETRIES = 3\n",
    "DRY_RUN_LIMIT_PER_SERIES = None     # e.g., 25 to test\n",
    "RPM_LIMIT = 10                       # throttle to 8 requests/rolling minute\n",
    "\n",
    "# 4) Text sanitizer for LLM input\n",
    "_ZERO_WIDTH_CODEPOINTS = [\n",
    "    \"\\uFEFF\", \"\\u00AD\", \"\\u200B\", \"\\u200C\", \"\\u200D\", \"\\u2060\", \"\\u2063\",\n",
    "    \"\\u200E\", \"\\u200F\", \"\\u202A\", \"\\u202B\", \"\\u202D\", \"\\u202E\", \"\\u202C\",\n",
    "    \"\\u2066\", \"\\u2067\", \"\\u2068\", \"\\u2069\",\n",
    "]\n",
    "_ZW_PATTERN = re.compile(\"|\".join(map(re.escape, _ZERO_WIDTH_CODEPOINTS)))\n",
    "_SPACE_MAP = {\"\\u00A0\": \" \", \"\\u202F\": \" \", \"\\u2007\": \" \"}\n",
    "\n",
    "def clean_text_for_llm(text: str, collapse_spaces: bool = True, keep_newlines: bool = True) -> str:\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    s = str(text).replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    s = unicodedata.normalize(\"NFKC\", s)\n",
    "    for k, v in _SPACE_MAP.items():\n",
    "        s = s.replace(k, v)\n",
    "    s = _ZW_PATTERN.sub(\"\", s)\n",
    "    def _is_bad(ch: str) -> bool:\n",
    "        cat = unicodedata.category(ch)\n",
    "        if ch in (\"\\n\", \"\\t\"):\n",
    "            return False\n",
    "        return cat in (\"Cc\", \"Cf\")\n",
    "    s = \"\".join(ch for ch in s if not _is_bad(ch))\n",
    "    if collapse_spaces:\n",
    "        s = s.replace(\"\\t\", \" \")\n",
    "        s = re.sub(r\"[ ]{2,}\", \" \", s)\n",
    "    s = \"\\n\".join(line.rstrip(\" \") for line in s.split(\"\\n\"))\n",
    "    if keep_newlines:\n",
    "        s = re.sub(r\"\\n{3,}\", \"\\n\\n\", s)\n",
    "    else:\n",
    "        s = \" \".join(s.split())\n",
    "    s = s.encode(\"utf-8\", \"replace\").decode(\"utf-8\")\n",
    "    return s\n",
    "\n",
    "def compose_message(base_prompt: str, issue_title: str, issue_body: str) -> str:\n",
    "    it = clean_text_for_llm(issue_title, collapse_spaces=False)\n",
    "    ib = clean_text_for_llm(issue_body,  collapse_spaces=False)\n",
    "    return f\"\"\"{base_prompt}\n",
    "\n",
    "Issue title: {it}\n",
    "Issue body: {ib}\"\"\"\n",
    "\n",
    "def call_gemini_classify(client: genai.Client, model: str, message: str) -> str:\n",
    "    last_err = None\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            resp = client.models.generate_content(\n",
    "                model=model,\n",
    "                contents=message,\n",
    "                config={\"temperature\": TEMPERATURE},\n",
    "            )\n",
    "            return (getattr(resp, \"text\", \"\") or \"\").strip()\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(min(2 ** attempt, 8))  # 1s,2s,4s,8s capped\n",
    "    print(f\"⚠️  Gemini call failed after {MAX_RETRIES} retries: {last_err}\")\n",
    "    return \"\"\n",
    "\n",
    "# 5) Sliding-window rate limiter (8 RPM)\n",
    "class PerMinuteLimiter:\n",
    "    \"\"\"Allow at most `max_calls` in any rolling 60s window.\"\"\"\n",
    "    def __init__(self, max_calls: int):\n",
    "        self.max_calls = int(max_calls)\n",
    "        self._hits = deque()  # seconds timestamps of recent calls\n",
    "    def wait_for_slot(self):\n",
    "        now = time.time()\n",
    "        while self._hits and now - self._hits[0] >= 60.0:\n",
    "            self._hits.popleft()\n",
    "        if len(self._hits) < self.max_calls:\n",
    "            self._hits.append(now)\n",
    "            return\n",
    "        sleep_for = 60.0 - (now - self._hits[0]) + 0.01\n",
    "        if sleep_for > 0:\n",
    "            time.sleep(sleep_for)\n",
    "        self._hits.append(time.time())\n",
    "\n",
    "limiter = PerMinuteLimiter(RPM_LIMIT)\n",
    "\n",
    "# 6) Inputs & outputs\n",
    "gi_dir = Path(repo_root()) / \"gemini_input\"\n",
    "pred_dir = Path(repo_root()) / \"gemini_pred\"\n",
    "pred_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "series_csvs = sorted(gi_dir.glob(\"v*.csv\"))\n",
    "SERIES_WHITELIST = CFG.get(\"series_whitelist\") or []\n",
    "if SERIES_WHITELIST:\n",
    "    before = len(series_csvs)\n",
    "    series_csvs = [p for p in series_csvs if p.stem in set(SERIES_WHITELIST)]\n",
    "    print(f\"Applied series_whitelist={SERIES_WHITELIST} → {len(series_csvs)}/{before} remain\")\n",
    "\n",
    "if not series_csvs:\n",
    "    raise FileNotFoundError(f\"No input CSVs found in {gi_dir}. Run M7 first.\")\n",
    "\n",
    "print(\"Input series:\", [p.stem for p in series_csvs])\n",
    "\n",
    "# 7) Run (resumable)\n",
    "client = genai.Client(api_key=GEMINI_TOKEN)\n",
    "written = 0\n",
    "\n",
    "for csv_path in series_csvs:\n",
    "    series = csv_path.stem\n",
    "    out_csv = pred_dir / f\"{series}.csv\"\n",
    "\n",
    "    # Read input rows\n",
    "    with open(csv_path, \"r\", encoding=\"utf-8\", newline=\"\") as fh:\n",
    "        reader = csv.DictReader(fh)\n",
    "        in_rows = list(reader)\n",
    "\n",
    "    if not in_rows:\n",
    "        print(f\"⚠️  Empty input: {csv_path.name}\")\n",
    "        continue\n",
    "\n",
    "    # Load existing output (if any) to resume\n",
    "    existing_by_sha = {}\n",
    "    existing_fieldnames = None\n",
    "    if out_csv.exists():\n",
    "        with open(out_csv, \"r\", encoding=\"utf-8\", newline=\"\") as fh_out_in:\n",
    "            reader_out = csv.DictReader(fh_out_in)\n",
    "            existing_fieldnames = reader_out.fieldnames\n",
    "            for r in reader_out:\n",
    "                existing_by_sha[r.get(\"sha\")] = r\n",
    "\n",
    "    # Prepare output writer (rewrite file with merged rows; safe because we write as we go)\n",
    "    fieldnames = list(in_rows[0].keys())\n",
    "    if \"gemini_label\" not in fieldnames:\n",
    "        fieldnames += [\"gemini_label\"]\n",
    "\n",
    "    total = len(in_rows)\n",
    "    pbar = tqdm(total=total, desc=f\"{series}\", unit=\"row\", leave=True)\n",
    "\n",
    "    calls_made = 0\n",
    "    wrote = 0\n",
    "    reused = 0\n",
    "    skipped_no_issue = 0\n",
    "    newly_classified = 0\n",
    "\n",
    "    with open(out_csv, \"w\", encoding=\"utf-8\", newline=\"\") as fh_out:\n",
    "        w = csv.DictWriter(fh_out, fieldnames=fieldnames)\n",
    "        w.writeheader()\n",
    "\n",
    "        for idx, r in enumerate(in_rows, start=1):\n",
    "            sha    = (r.get(\"sha\") or \"\").strip()\n",
    "            ititle = (r.get(\"issue_title\") or \"\").strip()\n",
    "            ibody  = (r.get(\"issue_body\")  or \"\").strip()\n",
    "\n",
    "            # If we have an existing row for this sha and either:\n",
    "            #  - it has a non-empty gemini_label, OR\n",
    "            #  - the row has no issue content (we don't call API for those),\n",
    "            # then reuse that row (resume behavior).\n",
    "            existing = existing_by_sha.get(sha)\n",
    "            if existing:\n",
    "                existing_label = (existing.get(\"gemini_label\") or \"\").strip()\n",
    "                # prefer the existing row if it had a label already, or no issue content\n",
    "                if existing_label or (not ititle and not ibody):\n",
    "                    # make sure all columns are present (in case input columns changed)\n",
    "                    row_to_write = {k: existing.get(k, r.get(k, \"\")) for k in fieldnames}\n",
    "                    w.writerow(row_to_write)\n",
    "                    wrote += 1\n",
    "                    reused += 1\n",
    "                    pbar.update(1)\n",
    "                    pbar.set_postfix_str(f\"{total - idx} remain (reused {reused})\")\n",
    "                    continue\n",
    "\n",
    "            # If no issue content → skip API, empty label\n",
    "            if not ititle and not ibody:\n",
    "                r[\"gemini_label\"] = \"\"\n",
    "                w.writerow(r)\n",
    "                wrote += 1\n",
    "                skipped_no_issue += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix_str(f\"{total - idx} remain (skipped {skipped_no_issue})\")\n",
    "                continue\n",
    "\n",
    "            # Optional dry-run limiter\n",
    "            if DRY_RUN_LIMIT_PER_SERIES is not None and calls_made >= DRY_RUN_LIMIT_PER_SERIES:\n",
    "                r[\"gemini_label\"] = \"\"\n",
    "                w.writerow(r)\n",
    "                wrote += 1\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix_str(f\"{total - idx} remain (dry-run)\")\n",
    "                continue\n",
    "\n",
    "            # Compose & throttle\n",
    "            msg = compose_message(BASE_PROMPT, ititle, ibody)\n",
    "            limiter.wait_for_slot()\n",
    "\n",
    "            # Call Gemini\n",
    "            label = call_gemini_classify(client, GEMINI_MODEL, msg)\n",
    "            r[\"gemini_label\"] = label\n",
    "\n",
    "            w.writerow(r)\n",
    "            wrote += 1\n",
    "            newly_classified += 1\n",
    "            calls_made += 1\n",
    "\n",
    "            # progress\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"{total - idx} remain (new {newly_classified}, reused {reused})\")\n",
    "\n",
    "    pbar.close()\n",
    "    print(f\"✓ {series}: wrote {wrote} rows → {out_csv.name} | \"\n",
    "          f\"API calls: {calls_made}, reused: {reused}, no-issue: {skipped_no_issue}, new: {newly_classified}\")\n",
    "    written += 1\n",
    "\n",
    "print(f\"Done. Series written: {written}  →  Output dir: {pred_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb98f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target file: v4.2.csv\n",
      "603/603 processed — 0 remainnn\n",
      "✓ Updated: v4.2.csv — columns added/updated: gemini_pred_label, github_label (rows: 603)\n"
     ]
    }
   ],
   "source": [
    "# Update the most recent CSV in gemini_pred with:\n",
    "#   - gemini_pred_label: \"No Issue\" if no issue; else JSON[\"class\"] from gemini_label ('' if missing)\n",
    "#   - github_label: \"No Issue\" if no issue; else UI/Other/None based on labels\n",
    "import csv, json, re\n",
    "from pathlib import Path\n",
    "\n",
    "pred_dir = Path(repo_root()) / \"gemini_pred\"\n",
    "if not pred_dir.exists():\n",
    "    raise FileNotFoundError(f\"Not found: {pred_dir}. Run the Gemini prediction step first.\")\n",
    "\n",
    "# Pick the most recently modified v*.csv\n",
    "csv_files = sorted(pred_dir.glob(\"v*.csv\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No v*.csv files found in {pred_dir}\")\n",
    "target_csv = csv_files[0]\n",
    "print(f\"Target file: {target_csv.name}\")\n",
    "\n",
    "# --- helpers ---\n",
    "CODE_FENCE_RE = re.compile(r\"```(?:json|JSON)?\\s*(.*?)\\s*```\", re.DOTALL)\n",
    "FIRST_OBJECT_RE = re.compile(r\"\\{.*?\\}\", re.DOTALL)\n",
    "CLASS_PAIR_RE  = re.compile(r'\"class\"\\s*:\\s*\"([^\"]+)\"')\n",
    "\n",
    "def has_issue_text(title: str, body: str) -> bool:\n",
    "    return bool((title or \"\").strip() or (body or \"\").strip())\n",
    "\n",
    "def extract_json_class(raw: str) -> str:\n",
    "    \"\"\"Return JSON['class'] from gemini_label (supports ```json ... ``` fences & noisy text).\"\"\"\n",
    "    if raw is None:\n",
    "        return \"\"\n",
    "    s = str(raw).strip()\n",
    "\n",
    "    # 1) If fenced, strip the fence\n",
    "    m = CODE_FENCE_RE.search(s)\n",
    "    if m:\n",
    "        s = m.group(1).strip()\n",
    "\n",
    "    # 2) Try direct JSON parse\n",
    "    try:\n",
    "        obj = json.loads(s)\n",
    "        if isinstance(obj, dict) and \"class\" in obj:\n",
    "            val = obj.get(\"class\")\n",
    "            return \"\" if val is None else str(val)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) Try to isolate first {...} blob and parse\n",
    "    m = FIRST_OBJECT_RE.search(s)\n",
    "    if m:\n",
    "        candidate = m.group(0)\n",
    "        try:\n",
    "            obj = json.loads(candidate)\n",
    "            if isinstance(obj, dict) and \"class\" in obj:\n",
    "                val = obj.get(\"class\")\n",
    "                return \"\" if val is None else str(val)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # 4) Last-resort regex\n",
    "    m = CLASS_PAIR_RE.search(s)\n",
    "    if m:\n",
    "        return m.group(1)\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def derive_github_label_from_issue(labels_primary: str, labels_alt: str) -> str:\n",
    "    \"\"\"\n",
    "    Labels → 'UI' / 'Other' / 'None'\n",
    "    - 'UI' if any label equals 'ui' (case-insensitive)\n",
    "    - 'Other' if labels exist but none are 'ui'\n",
    "    - 'None' if no labels\n",
    "    Accepts JSON list or comma/semicolon-separated text.\n",
    "    \"\"\"\n",
    "    data = labels_primary if (labels_primary and str(labels_primary).strip()) else labels_alt\n",
    "    if not data or str(data).strip() == \"\":\n",
    "        return \"None\"\n",
    "\n",
    "    raw = str(data).strip()\n",
    "    items = []\n",
    "    # Try JSON list first\n",
    "    try:\n",
    "        obj = json.loads(raw)\n",
    "        if isinstance(obj, list):\n",
    "            items = [str(x) for x in obj]\n",
    "    except Exception:\n",
    "        # Fallback to splitting\n",
    "        items = re.split(r\"[;,]\", raw)\n",
    "\n",
    "    tokens = [t.strip().lower() for t in items if str(t).strip()]\n",
    "    if not tokens:\n",
    "        return \"None\"\n",
    "    if any(t == \"ui\" for t in tokens):\n",
    "        return \"UI\"\n",
    "    return \"Other\"\n",
    "\n",
    "# --- read, update in place ---\n",
    "with open(target_csv, \"r\", encoding=\"utf-8\", newline=\"\") as fh:\n",
    "    rdr = csv.DictReader(fh)\n",
    "    rows = list(rdr)\n",
    "    base_fields = list(rdr.fieldnames or [])\n",
    "\n",
    "if not rows:\n",
    "    print(f\"⚠️  Empty file: {target_csv.name}\")\n",
    "else:\n",
    "    out_fields = base_fields[:]\n",
    "    for col in (\"gemini_pred_label\", \"github_label\"):\n",
    "        if col not in out_fields:\n",
    "            out_fields.append(col)\n",
    "\n",
    "    total = len(rows)\n",
    "    with open(target_csv, \"w\", encoding=\"utf-8\", newline=\"\") as fh_out:\n",
    "        w = csv.DictWriter(fh_out, fieldnames=out_fields)\n",
    "        w.writeheader()\n",
    "\n",
    "        for i, r in enumerate(rows, start=1):\n",
    "            ititle = (r.get(\"issue_title\") or \"\")\n",
    "            ibody  = (r.get(\"issue_body\")  or \"\")\n",
    "            has_issue = has_issue_text(ititle, ibody)\n",
    "\n",
    "            # gemini_pred_label\n",
    "            if not has_issue:\n",
    "                r[\"gemini_pred_label\"] = \"No Issue\"\n",
    "            else:\n",
    "                r[\"gemini_pred_label\"] = extract_json_class(r.get(\"gemini_label\"))\n",
    "\n",
    "            # github_label\n",
    "            if not has_issue:\n",
    "                r[\"github_label\"] = \"No Issue\"\n",
    "            else:\n",
    "                r[\"github_label\"] = derive_github_label_from_issue(\n",
    "                    r.get(\"issue_lable\"),  # your earlier spelling\n",
    "                    r.get(\"issue_label\")   # fallback if present\n",
    "                )\n",
    "\n",
    "            w.writerow(r)\n",
    "\n",
    "            # lightweight progress\n",
    "            if i % 50 == 0 or i == total:\n",
    "                print(f\"{i}/{total} processed — {total - i} remain\", end=\"\\r\")\n",
    "\n",
    "    print(f\"\\n✓ Updated: {target_csv.name} — columns added/updated: gemini_pred_label, github_label (rows: {total})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
